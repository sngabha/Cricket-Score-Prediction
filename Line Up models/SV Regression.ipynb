{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-computed stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(os.path.abspath('') + '\\\\..\\\\Derived stats\\\\match_stats_train.pkl')\n",
    "df_test = pd.read_pickle(os.path.abspath('') + '\\\\..\\\\Derived stats\\\\match_stats_test.pkl')\n",
    "\n",
    "# delete outlier\n",
    "\"\"\" Assuming, in most normal matches, teams \n",
    "score more than 75 runs on an average as shown\n",
    "by past statistics. \"\"\"\n",
    "df_train = df_train[df_train['Runs'] > 75]\n",
    "df_test = df_test[df_test['Runs'] > 75]\n",
    "\n",
    "cols = df_train.columns\n",
    "cols = cols.map(lambda x: x.replace(' ', '_') if isinstance(x, (str, 'utf-8')) else x)\n",
    "df_train.columns = cols\n",
    "df_test.columns = cols\n",
    "\n",
    "# To remove the other inning for which outliers were removed\n",
    "match_ids = df_test['Match_ID'].unique()\n",
    "m_ids_toBeRemoved = []          \n",
    "for m_id in match_ids:\n",
    "    if len(df_test[df_test['Match_ID'] == m_id]) !=2:\n",
    "        m_ids_toBeRemoved.append(m_id)\n",
    "\n",
    "for m_id in m_ids_toBeRemoved:\n",
    "    df_test = df_test[df_test['Match_ID'] != m_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding feature: Average runs scored against same opponent in previous matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Previous run with same opponent \"\"\"\n",
    "\n",
    "prev_run = []\n",
    "for Date, Team_Name, Opp_Team  in df_train[['Date','Team_Name', 'Opp_Team']].itertuples(index=False):\n",
    "    df_t = df_train.query(\"Team_Name == @Team_Name & Opp_Team == @Opp_Team & Date < @Date\")['Runs']\n",
    "    if len(df_t) == 0:\n",
    "        prev_run.append(df_train.query(\"Team_Name == @Team_Name & Opp_Team == @Opp_Team\")['Runs'].mean())\n",
    "        continue\n",
    "    prev_run.append(df_train.query(\"Team_Name == @Team_Name & Opp_Team == @Opp_Team & Date < @Date\")['Runs'].values[-1])\n",
    "df_train['Prev Run'] = prev_run\n",
    "\n",
    "prev_run = []\n",
    "for Date, Team_Name, Opp_Team  in df_test[['Date','Team_Name', 'Opp_Team']].itertuples(index=False):\n",
    "    df_t = df_test.query(\"Team_Name == @Team_Name & Opp_Team == @Opp_Team & Date < @Date\")['Runs']\n",
    "    if len(df_t) == 0:\n",
    "        df_t_t = df_train.query(\"Team_Name == @Team_Name & Opp_Team == @Opp_Team & Date < @Date\")\n",
    "        if len(df_t_t) == 0:\n",
    "            prev_run.append(0)\n",
    "        else:\n",
    "            prev_run.append(df_t_t['Runs'].values[-1])\n",
    "        continue\n",
    "    prev_run.append(df_test.query(\"Team_Name == @Team_Name & Opp_Team == @Opp_Team & Date < @Date\")['Runs'].values[-1])\n",
    "df_test['Prev Run'] = prev_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding feature: Average runs scored in a venue till date irrespective of teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Previous run on venue irrespective of team \"\"\"\n",
    "\n",
    "prev_run = []\n",
    "for Date, city  in df_train[['Date', 'City']].itertuples(index=False):\n",
    "    df_t = df_train.query(\"City == @city & Date < @Date\")\n",
    "    if len(df_t) == 0:\n",
    "        df_t_t = df_train.query(\"City == @city\")\n",
    "        if len(df_t_t) == 0:\n",
    "            prev_run.append(0)\n",
    "        else:\n",
    "            prev_run.append(df_t_t['Runs'].mean())\n",
    "        continue\n",
    "    prev_run.append(df_t['Runs'].mean())\n",
    "df_train['Prev Venue Run'] = prev_run\n",
    "\n",
    "prev_run = []\n",
    "for Date, city  in df_test[['Date', 'City']].itertuples(index=False):\n",
    "    df_te = df_test.query(\"City == @city & Date < @Date\")\n",
    "    df_tr = df_train.query(\"City == @city & Date < @Date\")\n",
    "    prev_run.append((df_te['Runs'].sum(axis = 0, skipna = True) + df_tr['Runs'].sum(axis = 0, skipna = True))/(len(df_te)+len(df_tr)))\n",
    "df_test['Prev Venue Run'] = prev_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print data before model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Features to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_inning_1 = df_train[df_train['Innnings'] == 1]\n",
    "df_test_inning_1 = df_test[df_test['Innnings'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inning_2 = df_test[df_test['Innnings'] == 2]\n",
    "inning_2_input = df_inning_2[['Avg_Bat1', 'Avg_Bat2', 'Avg_Bat3', 'Avg_Bat4', 'Avg_Bat5', 'Avg_Bat6', 'Avg_Bat7', 'Avg_Bat8', 'Avg_Bat9', 'Avg_Bat10', 'Avg_Bat11','Prev Run', 'Prev Venue Run', 'Past_lead']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train_inning_1[['Avg_Bat1', 'Avg_Bat2', 'Avg_Bat3', 'Avg_Bat4', 'Avg_Bat5', 'Avg_Bat6', 'Avg_Bat7', 'Avg_Bat8', 'Avg_Bat9', 'Avg_Bat10', 'Avg_Bat11', 'Prev Run', 'Prev Venue Run', 'Past_lead']]\n",
    "y_train = df_train_inning_1[['Runs']]\n",
    "\n",
    "X_test = df_test_inning_1[['Avg_Bat1', 'Avg_Bat2', 'Avg_Bat3', 'Avg_Bat4', 'Avg_Bat5', 'Avg_Bat6', 'Avg_Bat7', 'Avg_Bat8', 'Avg_Bat9', 'Avg_Bat10', 'Avg_Bat11','Prev Run', 'Prev Venue Run', 'Past_lead']]\n",
    "y_test = df_test_inning_1[['Runs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector Regressor with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0350s.) Setting batch_size=10.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  50 | elapsed:    0.0s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated',\n",
       "                           kernel='linear', max_iter=-1, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'C': array([3.12500000e-02, 6.75037337e-02, 1.45816130e-01, 3.14980262e-01,\n",
       "       6.80395000e-01, 1.46973449e+00, 3.17480210e+00, 6.85795186e+00,\n",
       "       1.48139954e+01, 3.20000000e+01])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_linear_grid_cv = GridSearchCV(estimator=SVR(kernel='linear'), param_grid={'C':np.logspace(-5, 5, num=10, base=2)}, cv= 5, iid=False, verbose=10, n_jobs = -1)\n",
    "svr_linear_grid_cv.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 24.758718723646993\n",
      "Test R2: -0.057016466283945855\n",
      "Test Explained Variance: 0.08328952877913942\n",
      "\n",
      "Train RMSE: 24.52398590326927\n",
      "Train R2: 0.309022670892905\n",
      "Train Explained Variance: 0.30911307414900524\n"
     ]
    }
   ],
   "source": [
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, svr_linear_grid_cv.predict(X_test))))\n",
    "print('Test R2:', r2_score(y_test, svr_linear_grid_cv.predict(X_test)))\n",
    "print('Test Explained Variance:', explained_variance_score(y_test, svr_linear_grid_cv.predict(X_test)))\n",
    "print()\n",
    "print('Train RMSE:', np.sqrt(mean_squared_error(y_train, svr_linear_grid_cv.predict(X_train))))\n",
    "print('Train R2:', r2_score(y_train, svr_linear_grid_cv.predict(X_train)))\n",
    "print('Train Explained Variance:', explained_variance_score(y_train, svr_linear_grid_cv.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of winner prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = pd.read_csv('matches.csv')\n",
    "matchId_winnerInning_dict = {}\n",
    "for index, row in matches.iterrows():\n",
    "    if row['winner'] == row['team1']:\n",
    "        matchId_winnerInning_dict[row['id']] = 1\n",
    "    if row['winner'] == row['team2']:\n",
    "        matchId_winnerInning_dict[row['id']] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohinish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666667\n"
     ]
    }
   ],
   "source": [
    "inning1_out = svr_linear_grid_cv.predict(X_test)\n",
    "inning2_out = svr_linear_grid_cv.predict(inning_2_input)\n",
    "\n",
    "winner_df = df_inning_2[['Match_ID']]\n",
    "winner = [ 1 if inning1_out[i] > inning2_out[i] else 2 for i in range(len(inning1_out))]\n",
    "winner_df['Winner'] = winner\n",
    "correct_count = 0\n",
    "for match_id, winner  in winner_df[['Match_ID', 'Winner']].itertuples(index=False):\n",
    "    if winner == matchId_winnerInning_dict[match_id]:\n",
    "        correct_count += 1\n",
    "winPredictionAccuracy = float((correct_count*100)/len(winner_df))\n",
    "\n",
    "print(winPredictionAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector Regressor with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0350s.) Setting batch_size=10.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  98 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 348 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 458 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 568 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 828 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 978 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1298 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated', kernel='rbf',\n",
       "                           max_iter=-1, shrinking=True, tol=0.001,\n",
       "                           verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'C': array([3.12500000e-02, 6.75037337e-02, 1.45816130e-01, 3.14980262e-01,\n",
       "       6.80395000e-01, 1.46973449e+00, 3.17480210e+00, 6.85795186e+00,\n",
       "       1.48139954e+01, 3.20000000e+01]),\n",
       "                         'degree': [1, 2, 3],\n",
       "                         'gamma': array([1.56250000e-02, 3.93725328e-02, 9.92125657e-02, 2.50000000e-01,\n",
       "       6.29960525e-01, 1.58740105e+00, 4.00000000e+00, 1.00793684e+01,\n",
       "       2.53984168e+01, 6.40000000e+01])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {'C':np.logspace(-5, 5, num=10, base=2), 'gamma':np.logspace(-6, 6, num=10, base=2), 'degree':[1,2,3]}\n",
    "svr_rbf_grid_cv = GridSearchCV(estimator=SVR(kernel='rbf'), param_grid=param_dict, cv= 5, iid=False, verbose=10, n_jobs = -1)\n",
    "svr_rbf_grid_cv.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 25.819389635271946\n",
      "Test R2: -0.14952220212881207\n",
      "Test Explained Variance: -0.01131349896834366\n",
      "\n",
      "Train RMSE: 10.596836971721524\n",
      "Train R2: 0.8709867877542454\n",
      "Train Explained Variance: 0.8710905847659012\n"
     ]
    }
   ],
   "source": [
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, svr_rbf_grid_cv.predict(X_test))))\n",
    "print('Test R2:', r2_score(y_test, svr_rbf_grid_cv.predict(X_test)))\n",
    "print('Test Explained Variance:', explained_variance_score(y_test, svr_rbf_grid_cv.predict(X_test)))\n",
    "print()\n",
    "print('Train RMSE:', np.sqrt(mean_squared_error(y_train, svr_rbf_grid_cv.predict(X_train))))\n",
    "print('Train R2:', r2_score(y_train, svr_rbf_grid_cv.predict(X_train)))\n",
    "print('Train Explained Variance:', explained_variance_score(y_train, svr_rbf_grid_cv.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of winner prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohinish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666667\n"
     ]
    }
   ],
   "source": [
    "inning1_out = svr_linear_grid_cv.predict(X_test)\n",
    "inning2_out = svr_linear_grid_cv.predict(inning_2_input)\n",
    "\n",
    "winner_df = df_inning_2[['Match_ID']]\n",
    "winner = [ 1 if inning1_out[i] > inning2_out[i] else 2 for i in range(len(inning1_out))]\n",
    "winner_df['Winner'] = winner\n",
    "correct_count = 0\n",
    "for match_id, winner  in winner_df[['Match_ID', 'Winner']].itertuples(index=False):\n",
    "    if winner == matchId_winnerInning_dict[match_id]:\n",
    "        correct_count += 1\n",
    "winPredictionAccuracy = float((correct_count*100)/len(winner_df))\n",
    "\n",
    "print(winPredictionAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector Regressor with sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0290s.) Setting batch_size=12.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 116 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 308 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 416 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 548 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 680 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 836 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 992 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1172 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1352 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed:    7.8s finished\n",
      "C:\\Users\\Mohinish\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
       "                           epsilon=0.1, gamma='auto_deprecated',\n",
       "                           kernel='sigmoid', max_iter=-1, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'C': array([3.12500000e-02, 6.75037337e-02, 1.45816130e-01, 3.14980262e-01,\n",
       "       6.80395000e-01, 1.46973449e+00, 3.17480210e+00, 6.85795186e+00,\n",
       "       1.48139954e+01, 3.20000000e+01]),\n",
       "                         'degree': [1, 2, 3],\n",
       "                         'gamma': array([1.56250000e-02, 3.93725328e-02, 9.92125657e-02, 2.50000000e-01,\n",
       "       6.29960525e-01, 1.58740105e+00, 4.00000000e+00, 1.00793684e+01,\n",
       "       2.53984168e+01, 6.40000000e+01])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_sigmoid_grid_cv = GridSearchCV(estimator=SVR(kernel='sigmoid'), param_grid=param_dict, cv= 5, iid=False, verbose=10, n_jobs = -1)\n",
    "svr_sigmoid_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 25.349022919295393\n",
      "Test R2: -0.10802068746925042\n",
      "Test Explained Variance: 0.0\n",
      "\n",
      "Train RMSE: 29.553954064953178\n",
      "Train R2: -0.0034895881520409233\n",
      "Train Explained Variance: 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, svr_sigmoid_grid_cv.predict(X_test))))\n",
    "print('Test R2:', r2_score(y_test, svr_sigmoid_grid_cv.predict(X_test)))\n",
    "print('Test Explained Variance:', explained_variance_score(y_test, svr_sigmoid_grid_cv.predict(X_test)))\n",
    "print()\n",
    "print('Train RMSE:', np.sqrt(mean_squared_error(y_train, svr_sigmoid_grid_cv.predict(X_train))))\n",
    "print('Train R2:', r2_score(y_train, svr_sigmoid_grid_cv.predict(X_train)))\n",
    "print('Train Explained Variance:', explained_variance_score(y_train, svr_sigmoid_grid_cv.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of winner prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohinish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666667\n"
     ]
    }
   ],
   "source": [
    "inning1_out = svr_linear_grid_cv.predict(X_test)\n",
    "inning2_out = svr_linear_grid_cv.predict(inning_2_input)\n",
    "\n",
    "winner_df = df_inning_2[['Match_ID']]\n",
    "winner = [ 1 if inning1_out[i] > inning2_out[i] else 2 for i in range(len(inning1_out))]\n",
    "winner_df['Winner'] = winner\n",
    "correct_count = 0\n",
    "for match_id, winner  in winner_df[['Match_ID', 'Winner']].itertuples(index=False):\n",
    "    if winner == matchId_winnerInning_dict[match_id]:\n",
    "        correct_count += 1\n",
    "winPredictionAccuracy = float((correct_count*100)/len(winner_df))\n",
    "\n",
    "print(winPredictionAccuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
